{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import numpy\n",
        "import os"
      ],
      "metadata": {
        "id": "l7hUEu3e-JwU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf.data pix2pix 버전(from tensor slice 버전)\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb#scrollTo=tyaP4hLJ8b4W"
      ],
      "metadata": {
        "id": "n2jTRC1228ux"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WuI6iO6GfKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brR2YK_vGfHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf.data classification 버전(list_files 버전)"
      ],
      "metadata": {
        "id": "hYMYdZK0x0-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6lCCU6j4ZuO",
        "outputId": "05670e32-e7c8-44fc-86a5-2e3de648f8f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "   creating: dataset/virabhadrasana ii/\n",
            "  inflating: dataset/virabhadrasana ii/42-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/43-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/43-1.png  \n",
            "  inflating: dataset/virabhadrasana ii/45-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/46-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/47-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/48-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/50-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/51-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/52-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/53-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/54-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/55-0.png  \n",
            "  inflating: dataset/virabhadrasana ii/File36.gif  \n",
            "   creating: dataset/virasana/\n",
            "  inflating: dataset/virasana/54-0.png  \n",
            "  inflating: dataset/virasana/57-0.png  \n",
            "  inflating: dataset/virasana/61-0.png  \n",
            "  inflating: dataset/virasana/70-0.png  \n",
            "  inflating: dataset/virasana/73-0.png  \n",
            "  inflating: dataset/virasana/75-0.png  \n",
            "  inflating: dataset/virasana/81-0.png  \n",
            "  inflating: dataset/virasana/81-1.png  \n",
            "  inflating: dataset/virasana/84-0.png  \n",
            "  inflating: dataset/virasana/90-0.png  \n",
            "  inflating: dataset/virasana/93-0.png  \n",
            "  inflating: dataset/virasana/95-0.png  \n",
            "  inflating: dataset/virasana/96-0.png  \n",
            "  inflating: dataset/virasana/97-0.png  \n",
            "  inflating: dataset/virasana/98-0.png  \n",
            "   creating: dataset/yoganidrasana/\n",
            "  inflating: dataset/yoganidrasana/41-0.png  \n",
            "  inflating: dataset/yoganidrasana/42-0.png  \n",
            "  inflating: dataset/yoganidrasana/43-0.png  \n",
            "  inflating: dataset/yoganidrasana/44-0.png  \n",
            "  inflating: dataset/yoganidrasana/45-0.png  \n",
            "  inflating: dataset/yoganidrasana/46-0.png  \n",
            "  inflating: dataset/yoganidrasana/48-0.png  \n",
            "  inflating: dataset/yoganidrasana/49-0.png  \n",
            "  inflating: dataset/yoganidrasana/55-0.png  \n",
            "  inflating: dataset/yoganidrasana/58-0.png  \n",
            "  inflating: dataset/yoganidrasana/73-0.png  \n",
            "  inflating: dataset/yoganidrasana/86-0.png  \n",
            "  inflating: dataset/yoganidrasana/87-0.png  \n",
            "  inflating: dataset/yoganidrasana/91-1.png  \n",
            "  inflating: dataset/yoganidrasana/97-0.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/dataset/\"\n",
        "image_count = len(list(glob.glob(data_dir+'*/*.png')))\n",
        "img_height = 28\n",
        "img_width = 28\n",
        "batch_size = 4"
      ],
      "metadata": {
        "id": "qoaVu60q-lo7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKxHzjtSAB-0",
        "outputId": "a6605572-5c1f-4fb7-fbb4-b07eac6fb8e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 ds 불러오기\n",
        "list_ds = tf.data.Dataset.list_files(data_dir+'*/*', shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
      ],
      "metadata": {
        "id": "u6sMzIpi-ifS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuktoNaI90QA",
        "outputId": "01755b01-8fc6-43c6-ceae-49d37a2a8e7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'/content/dataset/virasana/61-0.png'\n",
            "b'/content/dataset/virabhadrasana ii/55-0.png'\n",
            "b'/content/dataset/yoganidrasana/97-0.png'\n",
            "b'/content/dataset/virasana/90-0.png'\n",
            "b'/content/dataset/virasana/93-0.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 ds의 클래스 가져오기\n",
        "class_names = np.array(sorted(os.listdir(data_dir)))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97lEUlTlAuTx",
        "outputId": "47694c05-07b8-4bee-837d-9ba1f0ac5566"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['virabhadrasana ii' 'virasana' 'yoganidrasana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 ds를 split하기\n",
        "val_size = int(image_count * 0.2)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)"
      ],
      "metadata": {
        "id": "IC11gCXNAuKo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FbxV7V290LM",
        "outputId": "64ac2955-e2bc-4f2d-ab87-c37a6274ee7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 경로를 받아서 클래스 반환\n",
        "def get_label(file_path):\n",
        "  # Convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "metadata": {
        "id": "oD5CeILb90JA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 resize 하는 util 함수\n",
        "def decode_img(img):\n",
        "  # Convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  # Resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "metadata": {
        "id": "XXznnkMu90F3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 경로를 받아서 이미지와 라벨 반환\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # Load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "cACjhknw90Dk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "BlpH2oti90BN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_ds.take(5):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwwm-g7I9z-r",
        "outputId": "bca3a31b-1a84-464c-a012-30b62a746fb6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:  (28, 28, 3)\n",
            "Label:  0\n",
            "Image shape:  (28, 28, 3)\n",
            "Label:  0\n",
            "Image shape:  (28, 28, 3)\n",
            "Label:  2\n",
            "Image shape:  (28, 28, 3)\n",
            "Label:  2\n",
            "Image shape:  (28, 28, 3)\n",
            "Label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능을 위해 잘 섞고 배치 처리\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ],
      "metadata": {
        "id": "b7oTQsF-BbCk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "fvCatb8aCFMK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hU8k775ACKwR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq-AGb-aBa-d",
        "outputId": "a751125b-f5af-4e0d-90d7-8a3449aaec6e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "9/9 [==============================] - 2s 49ms/step - loss: 1.1258 - accuracy: 0.2778 - val_loss: 1.0867 - val_accuracy: 0.3750\n",
            "Epoch 2/3\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0952 - accuracy: 0.3056 - val_loss: 1.0864 - val_accuracy: 0.3750\n",
            "Epoch 3/3\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0806 - accuracy: 0.6111 - val_loss: 1.0765 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f932e90afa0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}